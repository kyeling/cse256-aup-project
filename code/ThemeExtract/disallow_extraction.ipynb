{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "M7QoAU7yg1BL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# I just upload all the AUPs in one folder\n",
        "dir = \"/content/drive/My Drive/project/AUP_project/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "oYF9gxXSNaIB",
        "outputId": "97dcbeb6-5369-409c-90c1-bb3335e44d79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "9zb4DpayMdt4",
        "outputId": "a6b6422d-4f51-4a81-b4a8-7cf0628ea993"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "Loading Gensim and nltk libraries\n",
        "'''\n",
        "# pip install gensim\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "np.random.seed(400)\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = []\n",
        "corpus = \"\"\n",
        "for fname in os.listdir(dir):\n",
        "    doc = open(f'{dir}{fname}', 'r', encoding='unicode_escape').read()\n",
        "    docs.append(doc)\n",
        "    corpus += doc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aQHb9XB3cf9T",
        "outputId": "38f831cc-8771-4660-cf8f-f78e1c99e803"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract disallows sentences"
      ],
      "metadata": {
        "id": "QXRinkLY6G51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# Define disallow keywords\n",
        "disallow_keywords = [\"disallow\", \"prohibit\", \"not allowed\", \"forbidden\", \"restricted\"]\n",
        "\n",
        "# Extract disallow statements using keyword matching\n",
        "disallow_statements = []\n",
        "disallow_corpus = \"\"\n",
        "for sentence in re.split('[.!?]\\n', corpus):\n",
        "    for keyword in disallow_keywords:\n",
        "        if keyword in sentence.lower():\n",
        "            disallow_statements.append(sentence.strip())\n",
        "            disallow_corpus += sentence.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aWgRlPVFQenU",
        "outputId": "3e569e54-de51-4646-80b6-7084e4713e3b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This one sometimes works but it's not working right now and I have no clue"
      ],
      "metadata": {
        "id": "7Pm2wRsE6X9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Text to be analyzed\n",
        "text = corpus\n",
        "# Process the text with spaCy\n",
        "doc = nlp(text)\n",
        "\n",
        "# Initialize a list to store disallowed activities\n",
        "disallowed_activities = []\n",
        "\n",
        "# Find the sentence containing the disallowed activities\n",
        "disallow_keywords = ['prohibited', 'violation', 'suspension', 'termination', 'hacking', 'spamming', 'malware', \"disallow\", \"prohibit\", \"not allowed\", \"forbidden\", \"restricted\"]\n",
        "\n",
        "# isBreak = False\n",
        "# for keyword in disallow_keywords:\n",
        "#   for sentence in doc.sents:\n",
        "#       if keyword in sentence.text.lower():\n",
        "#           disallowed_sentence = sentence\n",
        "#           isBreak = True\n",
        "#           break\n",
        "#   if isBreak:\n",
        "#     break\n",
        "\n",
        "for keyword in disallow_keywords:\n",
        "  for sentence in doc.sents:\n",
        "        if keyword in sentence.text.lower():\n",
        "            disallowed_sentence = sentence\n",
        "            break\n",
        "\n",
        "  # Extract disallowed activities from the disallowed sentence\n",
        "  for token in disallowed_sentence:\n",
        "      if token.pos_ == \"NOUN\":\n",
        "          disallowed_activities.append(token.text)\n",
        "\n",
        "  # Get the top 10 disallowed activities\n",
        "  top_10_disallowed_activities = disallowed_activities[:10]\n",
        "\n",
        "  # Print the top 10 disallowed activities\n",
        "  print(f\"Trying keyword {keyword}: \")\n",
        "  for i, activity in enumerate(top_10_disallowed_activities, 1):\n",
        "      print(f\"{i}. {activity}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u1QBiC6FolQE",
        "outputId": "7ce84005-d1d5-43b5-d329-4255790ef377"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying keyword prohibited: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "Trying keyword violation: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "Trying keyword suspension: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword termination: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword hacking: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword spamming: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword malware: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword disallow: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword prohibit: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword not allowed: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword forbidden: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n",
            "Trying keyword restricted: \n",
            "1. USES\n",
            "2. site\n",
            "3. purposes\n",
            "4. Violations\n",
            "5. Policy\n",
            "6. .\n",
            "7. TERMINATION\n",
            "8. discretion\n",
            "9. breach\n",
            "10. use\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This one doesn't make sense"
      ],
      "metadata": {
        "id": "opft3UjZ5szY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rake_nltk import Rake\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Text to be analyzed\n",
        "text = disallow_corpus\n",
        "\n",
        "# Initialize the RAKE object\n",
        "r = Rake()\n",
        "\n",
        "# Extract keywords\n",
        "r.extract_keywords_from_text(text)\n",
        "\n",
        "# Get the top 10 keywords\n",
        "top_10_keywords = r.get_ranked_phrases()[:10]\n",
        "\n",
        "# Print the top 10 keywords\n",
        "for i, keyword in enumerate(top_10_keywords, 1):\n",
        "    print(f\"{i}. {keyword}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "kdYYvTp7s12S",
        "outputId": "d665fd63-1e2e-4953-d8a8-45f5f5e07614"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. callbacknavigation navigation navigation navigation exams exams supercoaching live classes header_free test series skill academy select courses practice pass pass pro gk\n",
            "2. streaming media serversproxy serversremote adminstration serversdns serversdhcp serversx serverstelnet serversssh serversprint serverstftp serversmessaging serversmud serversicq serverschat serversirc serversdatabase serversfile\n",
            "3. streaming media serversproxy serversremote adminstration serversdns serversdhcp serversx serverstelnet serversssh serversprint serverstftp serversmessaging serversmud serversicq serverschat serversirc serversdatabase serversfile\n",
            "4. streaming media serversproxy serversremote adminstration serversdns serversdhcp serversx serverstelnet serversssh serversprint serverstftp serversmessaging serversmud serversicq serverschat serversirc serversdatabase serversfile\n",
            "5. exams english hindi get started get started english hindi get started get pass pro renew pass pro get pass pro upgrade\n",
            "6. appsasian tv channelsvirgin tv channelsvirgin tv 360 boxlandlinelandline packageslandline calling featureslandline international callsmobilepay monthly phonespay monthly tabletsapple iphonessamsung galaxy phonesphones\n",
            "7. productsfeatures accept payments onlinecash flow managementexpense trackerinventory trackinginvoice softwarejob costingmanage billsmaximize tax deductionsmileage trackerpayroll softwarerun reportstime tracking softwaretrack sales\n",
            "8. pass pro exams super coaching test series skill academy pass pass pass pro header_more free live classes live tests\n",
            "9. quizzes previous year papers practice header_quizzes header_attempted_tests pass pass pro header_miscellaneous exams exams header_saved_ques header_reported_ques header_doubts gk\n",
            "10. selections home tests super practice pass pass pro get app exams tests super practice get app acceptable use policy testbook provides\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}