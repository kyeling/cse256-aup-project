{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"aQGLVHVBAlkV"},"source":["## Part 0: Set-up"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22778,"status":"ok","timestamp":1684648915052,"user":{"displayName":"Kyeling Ong","userId":"17310599495446242134"},"user_tz":420},"id":"02kQ2WRyApO8","outputId":"2daf71eb-2347-47d4-f5b1-b7650296eb82"},"outputs":[],"source":["%load_ext autoreload \n","%autoreload 2\n","\n","import pandas as pd\n","from multiprocessing import Process\n","import data"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"E_Kk8RoqHLeO"},"source":["## Part 1: Initial data collection\n","Data comes from the CrUX dataset. More information can be found at https://github.com/zakird/crux-top-lists"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2730,"status":"ok","timestamp":1684648927884,"user":{"displayName":"Kyeling Ong","userId":"17310599495446242134"},"user_tz":420},"id":"VdIkfEMX5pS8","outputId":"58a65cc2-557a-4143-da89-bb602cfddbbf"},"outputs":[],"source":["# create dataframe\n","df = data.get_dataset().reset_index()\n","ranks = df['rank'].unique()\n","print(df)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PW76RP_XHQRu"},"source":["## Part 2: Searching for AUPs\n","Get the data in batches by rank (1k, 5k, 10k)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2TdK9KQaXCn0","outputId":"ea5b7694-5e69-4bbd-c039-1ed757f92d73"},"outputs":[],"source":["# run code, sit back, and wait ...\n","for r in ranks[:3]:\n","    rank_df = data.rank_filter(df, r)\n","    data.get_aups_in_bucket(rank_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get aups in a combined dataframe for scraping\n","url_df = pd.concat([pd.read_csv(f'../data/aup-urls/crux-aups-rank{r}.csv') for r in ranks[:3]])\n","uniq_url_df = url_df.groupby('aup').min().reset_index()\n","\n","print(uniq_url_df)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# scrape aup contents\n","for i in range(len(uniq_url_df)):\n","    row = uniq_url_df.iloc[i]\n","    idx = row['index']\n","    aup = row['aup']\n","\n","    fname = f'../data/crux-aups/{str(idx).zfill(4)}-current.txt'\n","    p = Process(target=data.get_aup_content, args=[aup, fname])\n","    p.start()\n","    p.join(timeout=10)\n","    p.terminate()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# scrape aup contents of aup urls retrieved through google search \n","crux_urls = uniq_url_df['aup'].values\n","googlesearch_urls = open('../data/aup-urls/googlesearch-aups.txt').readlines()\n","\n","for idx, aup in enumerate(googlesearch_urls):\n","    if aup in crux_urls:\n","        continue\n","    \n","    fname = f'../data/googlesearch-aups/{str(idx).zfill(3)}-current.txt'\n","    p = Process(target=data.get_aup_content, args=[aup, fname])\n","    p.start()\n","    p.join(timeout=10)\n","    p.terminate()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Obtaining master csv file for final dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","import csv\n","\n","datapath = 'data/final_data/'\n","cruxpath = f'../{datapath}crux/'\n","googlepath = f'../{datapath}googlesearch/'\n","github_url = f'https://github.com/kyeling/cse256-aup-project/tree/main/{datapath}'\n","\n","with open('../data/master.csv', newline='', mode='w') as f:\n","    w = csv.writer(f)\n","    w.writerow(['id', 'source', 'url', 'filepath', 'link-to-filepath', 'sector'])\n","\n","    crux_df = pd.read_csv('../data/aup-urls/crux-aups.csv')\n","    crux_df = crux_df.set_index('index')\n","    for fname in os.listdir(cruxpath):\n","        if fname == '.gitignore': continue\n","        id, _ = fname.split('-')\n","        url = crux_df.loc[int(id)]['aup']\n","        w.writerow([id, 'crux', url, fname, f'{github_url}/crux/{fname}'])\n","\n","    googlesearch_list = open('../data/aup-urls/googlesearch-aups.txt').readlines()\n","    for fname in os.listdir(googlepath):\n","        if fname == '.gitignore': continue\n","        id, _ = fname.split('-')\n","        url = googlesearch_list[int(id)].replace('\\n', '')\n","        w.writerow([id, 'googlesearch', url, fname, f'{github_url}/googlesearch/{fname}'])"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
